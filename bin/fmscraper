#!/usr/bin/env python3

from urllib.request import urlopen
from bs4 import BeautifulSoup
import argparse
import csv
import sys

def writecsv(releases, separator):
    fieldnames = ['version', 'timestamp', 'note']
    writer = csv.DictWriter(sys.stdout, fieldnames=fieldnames, delimiter=separator)
    writer.writeheader()
    for release in releases:
        writer.writerow(release)

def scrape(application):
    quote_page = "http://freshmeat.sourceforge.net/projects/" + application
    # query the website and return the html to the variable ‘page’
    page = urlopen(quote_page)
    # parse the html using beautiful soup and store in variable `soup`
    #soup = BeautifulSoup(page, ‘html.parser’)
    soup = BeautifulSoup(page, "html.parser")
    boo = soup.find('div', attrs={'class': 'recent-releases'})
    #print(boo.prettify())
    children = boo.find_all("div", {} ,recursive=False)
    releases = []
    for child in children:
        #print("------")
        version = child.find('li', {'class': 'release'}).find('a').text
        rdateString = child.find('li', {'class': 'rdate'}).text
        note = child.find('p', {'class': 'truncate changes'}).text
        #print(version)
        #print(rdateString)
        #print(note)
        #print("******")
        releases.append({"version" : version.strip(), "timestamp" : rdateString.strip(), "note" : note.strip()})
        #print(child.prettify())
    return releases

def main(args):
    releases = scrape(args.application)
    writecsv(releases, args.separator)


parser = argparse.ArgumentParser(description='''
    Freshmeat.net screen scraper retrieves software release timeline
    information for specified application.
    Output consists of a line for each release to standard out in the CSV format. The
    fields retrieved include the release version number, the date of the
    release and the release notes associated with the release.
    ''',
    formatter_class=lambda prog: argparse.HelpFormatter(prog,max_help_position=50))
parser.add_argument("-s","--separator", choices=['|','#'],  help="CSV field separator (default is ',')", default=",")
parser.add_argument("application", help="Retrive timeline for this application")

args = parser.parse_args()
main(args)
